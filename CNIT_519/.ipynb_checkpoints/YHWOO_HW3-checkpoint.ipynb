{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDuu1oSpXykF"
   },
   "source": [
    "# Yoonhyuck WOO / Purdue University_Computer and Information Technology\n",
    "# Title: Analyzing Contextualized Word Embeddings for knowledge of word-senses\n",
    "# Professor: Julia Rayz, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6w1f1r9_7iY"
   },
   "source": [
    "\n",
    "# Reference: By Kanishka Misra (kmisra@purdue.edu)\n",
    "\n",
    "\n",
    "The goal of this assignment is to get you to be familiarized in dealing with vectors computed by (roughly) state of the art pre-trained language models.\n",
    "\n",
    "Recall from Tuesday's lecture that language modeling is a commonly used method for training neural-network-based sequence models, and allows them to learn vector representations of words *in context.* For instance, every layer of the BERT model represents a word by relying on **all other words** in the sentence context that the word occurs in.\n",
    "\n",
    "This may lead us to hypothesize that BERT could have attained a decent competency in representing lexical ambiguity -- a phenomena when the same word has multiple meanings.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## A brief primer on lexical ambiguity\n",
    "\n",
    "Lexical ambiguity manifests in language in two elementary ways:\n",
    "\n",
    "The first way is when the same word has multiple meanings that are related. In this case, what we have is an instance of **polysemy**:\n",
    "\n",
    "Consider the many polysemous senses of the word **face** (taken from [WordNet](http://wordnetweb.princeton.edu/perl/webwn?s=face&sub=Search+WordNet&o2=&o0=1&o8=1&o1=1&o7=&o5=&o9=&o6=1&o3=&o4=&h=000000)):\n",
    "  1. (n) the front of the human head from the forehead to the chin and ear to ear. E.g., *his **face** was injured*\n",
    "  2. (n) the feelings expressed on a person's face. E.g., *his angry **face**.*\n",
    "  3. (n) the general outward appearance of something. E.g., *the **face** of the city is changing* (metaphorically related)\n",
    "  4. ... (including anything else that is related to the three above)\n",
    "\n",
    "The second way is when two or more distinct, unrelated meanings happen to have the same word form (this usually happens by coincidence). In this case, we have an instance of **homonymy** (when two words share sounds, it is called **homophony**).\n",
    "\n",
    "Consider the following senses of the word form **bow**:\n",
    "\n",
    "  1. (n) a slightly curved piece of resilient wood with taut horsehair strands; used in playing certain stringed instruments. *She checked on her **bow** before performing that night.*\n",
    "  2. (n) bending the head or body or knee as a sign of reverence or submission or shame or greeting. *He dropped into a **bow** before them.*\n",
    "  3. (n) a weapon for shooting arrows, composed of a curved piece of resilient wood with a taut cord to propel the arrow. *a **bow** and arrow.*\n",
    "\n",
    "Coming back to our assignment -- our goal here is to analyze a given model's (or more models, upto you) behavior in representing the above lexical phenomena.\n",
    "\n",
    "---\n",
    "\n",
    "## Analysing lexical ambiguity in models\n",
    "\n",
    "While there are several ways in which one can test for lexical ambiguity, we will be using the notion of vector space similarity.\n",
    "It would be reasonable to suggest that vectors of words that have the same or related senses should be much closer together as opposed to words that do not. That is, the vectors for the word **bank** in (1.) should be closer to that in (2.), than to that in (3.):\n",
    "\n",
    "1. *I went to the **bank** to withdraw some cash.*\n",
    "2. *John had an appointment with the manager of the **bank** yesterday.*\n",
    "3. *They pulled the canoe up on the **bank**.*\n",
    "\n",
    "This closeness can be measured by the cosine similarity:\n",
    "\n",
    "$$\n",
    "cos(\\pmb x, \\pmb y) = \\frac {\\pmb x \\cdot \\pmb y}{||\\pmb x|| \\cdot ||\\pmb y||}\n",
    "$$\n",
    "\n",
    "Therefore a good model will show us the following result: $cos(bank_1, bank_2) > cos(bank_1, bank_3)$. This is exactly what we will be exploring in this homework.\n",
    "\n",
    "---\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "A document (pdf, or any other format) that has a description of your results and discussions. Each question following the demo has its own set of discussion content. **Code is optional, but feel free to include it. We will be mostly paying attention to the discussion and results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BgI-I7yNthx"
   },
   "source": [
    "## Getting started\n",
    "\n",
    "\n",
    "\n",
    "We will begin by installing my package, `minicons`.\n",
    "If you are interested, check out its [documentation](https://minicons.kanishka.website) (still in active development). I have also made \"getting started examples\" for the package. They can be found [here](https://github.com/kanishkamisra/minicons/blob/master/examples/word_representations.md).\n",
    "\n",
    "I wrote this package to make it easy to extract representations for words from pre-trained LMs. It also contains other very important utilities that we may use in this class at some point.\n",
    "\n",
    "To install the package, click on the grey cell below, and either click \"play\" to the left of the cell, or hit `shift + tab` which will run the cell and take you to the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOXQfG-VAmJ6",
    "outputId": "d53a2024-8933-4267-9078-bf21eccae447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minicons in /usr/local/lib/python3.10/dist-packages (0.2.19)\n",
      "Requirement already satisfied: openai<0.29.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from minicons) (0.28.1)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from minicons) (1.5.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from minicons) (8.2.3)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from minicons) (2.0.1+cu118)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from minicons) (4.34.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from minicons) (1.26.17)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<0.29.0,>=0.28.0->minicons) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<0.29.0,>=0.28.0->minicons) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<0.29.0,>=0.28.0->minicons) (3.8.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.5->minicons) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.5->minicons) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.5->minicons) (1.23.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3.0.0,>=2.0.0->minicons) (3.27.6)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3.0.0,>=2.0.0->minicons) (17.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.30.0->minicons) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.30.0->minicons) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.30.0->minicons) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.30.0->minicons) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.30.0->minicons) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.30.0->minicons) (0.4.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers<5.0.0,>=4.30.0->minicons) (2023.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.3.5->minicons) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29.0,>=0.28.0->minicons) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29.0,>=0.28.0->minicons) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29.0,>=0.28.0->minicons) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->minicons) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.0->minicons) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install minicons # will show an error towards the end, but that's not an error in the installation, so worry not!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-N9pjyYfOh4r"
   },
   "source": [
    "The above code may have shown an error saying `ERROR: pip's dependency resolver...`, but that is google's internal problem. The package should be installed regardless.\n",
    "\n",
    "Next, load some useful libraries that we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKrvu-BEAtYM"
   },
   "outputs": [],
   "source": [
    "from minicons import cwe\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPAT4Jr4O4WQ"
   },
   "source": [
    "We will then write code to compute the cosine similarity between two vectors (or tensors, in general; you do not have to worry about this for the purposes of this homework, but feel free to ask us questions separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "og61rI1aJD16"
   },
   "outputs": [],
   "source": [
    "def cosine(a: torch.Tensor, b: torch.Tensor, eps = 1e-8) -> torch.Tensor:\n",
    "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
    "    b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
    "    sims = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usYFpECI_H1i"
   },
   "source": [
    "# Loading pre-trained models\n",
    "\n",
    "We are now ready to load our first pre-trained model!\n",
    "\n",
    "For simplicity, I will show this demo on the `bert-base-uncased` model, the smallest official BERT model released in the original paper.\n",
    "\n",
    "Every pre-trained model that can be loaded by minicons is an instance of the `cwe.CWE` class. `CWE` stands for 'contextual word embeddings'\n",
    "\n",
    "BERT, RoBERTa, etc., are all instances of contextual word embeddings, since they emit vectors that take their input context into account.\n",
    "\n",
    "In theory, any model that is part of the [huggingface hub](https://huggingface.co/models) can be loaded with this class.\n",
    "\n",
    "To load bert-base, run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9o_-SqH7RCpx"
   },
   "source": [
    "# Extracting representations of words (and phrases)\n",
    "\n",
    "The function primarily used for extracting representations from models is `model.extract_representation()`. It accepts batches of instances represented in either of the following formats:\n",
    "\n",
    "```\n",
    "data = [\n",
    "  (sentence_1, word_1),\n",
    "  (sentence_2, word_2),\n",
    "  ....\n",
    "  (sentence_n, word_n)\n",
    "]\n",
    "```\n",
    "where `word_i` is the word whose vector is to be extracted from its corresponding sentence (`sentence_i`)\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "data = [\n",
    "  (sentence_1, (start_1, end_1)),\n",
    "  (sentence_2, (start_2, end_2)),\n",
    "  ....\n",
    "  (sentence_n, (start_n, end_n))\n",
    "]\n",
    "```\n",
    "where `(start_i, end_i)` are the character span indices for the target word in the ith sentence, i.e., `start_i` is the start index, and `end_i` is the end index.\n",
    "\n",
    "For example, the entry `[\"I like reading books.\", (15, 20)]` corresponds to the word `\"books\"`, because\n",
    "\n",
    "```python\n",
    "\"I like reading books.\"[15:20] = \"books\"\n",
    "```\n",
    "\n",
    "To keep things simple, I will be using sentences where a word only occurs once, and use the first method of representing the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qfjizOVDtMz"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "        ['The quick brown fox jumped over the lazy dog.', 'fox'],\n",
    "        ['The slow pink fox ran into the fast cat.', 'fox']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kw3SkuzSvt73",
    "outputId": "797cd90f-4fec-495b-c807-73c5573c210f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumped over the lazy dog.', 'fox']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAo6jGm3SrT6"
   },
   "source": [
    "\n",
    "The `model.extract_representation` function also takes another parameter, `layer`.\n",
    "\n",
    "Recall from earlier class that pre-trained LMs usually have multiple layers. To find out how many layers a model has, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4tnbictUCQj",
    "outputId": "8b447fb2-228e-454c-f5aa-5eab608fa83c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzxUkwFCU-Gn"
   },
   "source": [
    "Note that the 12 layers here means that there have been 12 total \"multi-headed self attention\" operations. Apart from this, the model also contains a 0th layer, which consists of representations that are passed to the first self-attention layer. These representations are composed of the static embeddings of the model (one for each word) which are combined with the position and segment embeddings using vector-addition.\n",
    "\n",
    "By default, minicons uses the model's last layer.\n",
    "\n",
    "\n",
    "Let us now extract embeddings from the structure we created earlier (the sentences containing the word 'fox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_EDU9h2GOvq"
   },
   "outputs": [],
   "source": [
    "embedding = model.extract_representation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ECAa0aNWFvD",
    "outputId": "58c67a09-6b23-4f26-f85a-3ef76d9f259a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0571, -0.2493, -0.3621,  ..., -0.3584,  0.2380,  0.3966],\n",
       "        [-0.1199, -0.7536, -0.3551,  ..., -0.5651,  0.4172,  0.6888]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding # embeddings of the word fox in the sentences contained in `data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kX_LW6ZM1JEV"
   },
   "source": [
    "The result is interpreted as follows:\n",
    "\n",
    "```\n",
    "tensor([[-0.0571, -0.2493, -0.3621,  ..., -0.3584,  0.2380,  0.3966], <- embedding for the first instance\n",
    "        [-0.1199, -0.7536, -0.3551,  ..., -0.5651,  0.4172,  0.6888]]) <- embedding for the second instance\n",
    "```\n",
    "\n",
    "`bert-base` encodes words in a 768 dimensional vector, you can check the dimensions of the above result using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oENdv4S151z",
    "outputId": "2584000b-3028-4e1c-d03f-05e1a72e4dc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape # 2 vectors of 768 dimensions each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpXz1cAe2Gu4"
   },
   "source": [
    "Let us now compute the cosine similarity of the two fox-sentences. While there are a number of different ways of doing this, we will take the similarity of the above result with itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3wW9DRDKhAa",
    "outputId": "441e9497-901f-4e15-ee79-5b80bf784f81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9278],\n",
       "        [0.9278, 1.0000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise = cosine(embedding, embedding)\n",
    "pairwise # notice that cosine is symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTwjeGhj2RRJ"
   },
   "source": [
    "The top right (or bottom left) value is the similarity of the two fox-words, we can access it by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKYnMvK2LlHN",
    "outputId": "c9611bf1-5973-4951-80d8-71aef9a718de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9278209209442139"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise[0,1].item() # similarity of fox in the  first sentence with that in second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eD2tDV03wkz"
   },
   "source": [
    "## An example\n",
    "\n",
    "Let us now apply our knowledge about computing similarities with contextualized word representations to test how well BERT represents lexical ambiguity.\n",
    "\n",
    "We will adopt the paradigm of defining a set of query instances (sentence-word pairs) and take each instance's similarity with a set of reference sentence-word pairs.\n",
    "\n",
    "In the following case, we have (focus word bolded) the following queries:\n",
    "\n",
    "1. Please just **book** me a place to stay already, will you!\n",
    "2. I'll **reserve** those tickets shortly.\n",
    "3. I liked reading that **book**.\n",
    "\n",
    "Similarly, we have the following references:\n",
    "\n",
    "1. My children said the will **book** us a trip to Hawaii!\n",
    "2. Please just buy the **book** already, will you!\n",
    "3. Lester, can you **book** my entire schedule for all of Monday?\n",
    "\n",
    "**Exercise for the reader:** What words should be more similar to each other? (Notice the contexts for query 1 and reference 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmdQs0uoGaF8"
   },
   "outputs": [],
   "source": [
    "query = [\n",
    "         [\"Please just book me a place to stay already, will you!\", \"book\"],\n",
    "         [\"I'll reserve those tickets shortly.\", \"reserve\"],\n",
    "         [\"I liked reading that book!\", \"book\"] # Noun\n",
    "] # question\n",
    "\n",
    "reference = [\n",
    "             [\"My children said they will book us a trip to Hawaii!\", \"book\"], # Verb\n",
    "             [\"Please just buy the book already, will you!\", \"book\"], # Noun\n",
    "             [\"Lester, can you book my entire schedule for all of Monday?\", \"book\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFyooOYEI_Ff"
   },
   "outputs": [],
   "source": [
    "# Extract embeddings for each set of instances, for demonstration, let us look at the second last layer (11)\n",
    "reference_emb = model.extract_representation(reference, layer = 11)\n",
    "query_emb = model.extract_representation(query, layer = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cI2bCeSFJILQ",
    "outputId": "7cde8c24-0880-44ee-986c-4512ad8328de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7540, 0.4687, 0.6881],\n",
       "        [0.5885, 0.3825, 0.6178],\n",
       "        [0.5589, 0.8250, 0.5271]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the cosine of every query with every reference\n",
    "sims = cosine(query_emb, reference_emb)\n",
    "\n",
    "# explore the output:\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlFXuYZMVnyI",
    "outputId": "7882fb54-23f6-4e24-acc4-b828c1a80567"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7540, 0.4687, 0.6881])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the similarity between the first query, \"My children...\", and the reference list:\n",
    "sims[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WUJTMATfBBn"
   },
   "source": [
    "We see that the similarity of \"book\" in *My children said they will **book**...* with:\n",
    "1. first reference is 0.754\n",
    "2. second reference is 0.469\n",
    "3. third reference is 0.688\n",
    "\n",
    "Which means, the \"book\" in first question is closest to the \"book\" in:\n",
    "\n",
    "\"Please just **book** me a place to stay already, will you!\"\n",
    "\n",
    "\n",
    "we can make the process of looking at \"the closest\" embedding a little easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EiMb0JoWBdY",
    "outputId": "a670b86f-73da-4468-b0a9-69bb854d62e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['Please just book me a place to stay already, will you!', 'book']\n",
      "Closest Reference: ['My children said they will book us a trip to Hawaii!', 'book']\n"
     ]
    }
   ],
   "source": [
    "# For the first query, what is the closest usage of the book in the reference set?\n",
    "\n",
    "closest1 = reference[sims[0].argmax().item()] # argmax finds the index with the greatest value, in this case, the greatest similarity!\n",
    "\n",
    "print(f\"Query: {query[0]}\\nClosest Reference: {closest1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wHjaB7AXGQ5",
    "outputId": "e2296108-384c-4095-e15d-b4733d958421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: [\"I'll reserve those tickets shortly.\", 'reserve']\n",
      "Closest Reference: ['Lester, can you book my entire schedule for all of Monday?', 'book']\n"
     ]
    }
   ],
   "source": [
    "# Repeating the same for the second query:\n",
    "closest2 = reference[sims[1].argmax().item()] # argmax finds the index with the greatest value, in this case, the greatest similarity!\n",
    "\n",
    "print(f\"Query: {query[1]}\\nClosest Reference: {closest2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RjikFiRyWJ_u",
    "outputId": "61eea313-1649-4f34-8818-15dc2479a07b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7540, 0.4687, 0.6881],\n",
       "        [0.5885, 0.3825, 0.6178],\n",
       "        [0.5589, 0.8250, 0.5271]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMVv8hBCV9yE",
    "outputId": "69b2b7cc-61fe-4434-a975-f1c4b606ef80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['I liked reading that book!', 'book']\n",
      "Closest Reference: ['Please just buy the book already, will you!', 'book']\n"
     ]
    }
   ],
   "source": [
    "# Third query:\n",
    "closest3 = reference[sims[2].argmax().item()] # argmax finds the index with the greatest value, in this case, the greatest similarity!\n",
    "\n",
    "print(f\"Query: {query[2]}\\nClosest Reference: {closest3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfQ0C-rtV6_l"
   },
   "source": [
    "We see here that in all cases, BERT-base (layer 11) prefers the correct reference! Although to conclude about this more broadly, we'd need a large dataset of diverse sentences.\n",
    "\n",
    "Now, it's your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDfsfSduX1lR"
   },
   "source": [
    "# Assignment objectives\n",
    "\n",
    "Using the code from above, your objectives are as follows:\n",
    "\n",
    "**Preliminary:** Select a model and layer of your choice. Here are some suggested options (`Name: <identifier to be used in cwe.CWE()>, <number of layers>`):\n",
    "```\n",
    "BERT-base: bert-base-uncased, 12 layers\n",
    "BERT-large: bert-large-uncased, 24 layers\n",
    "RoBERTa-base: roberta-base, 12 layers\n",
    "RoBERTa-large: roberta-large, 24 layers\n",
    "```\n",
    "\n",
    "If you want to be a little adventurous, check out other models here: https://huggingface.co/models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONxjb8INXuJD"
   },
   "source": [
    "## Question 1: Same words, different meanings\n",
    "\n",
    "Analyze your model (and layer) on a new polysemous/homonymous word (should at least contain 2 different senses of the word) using the same format as above:\n",
    "\n",
    "```\n",
    "query = list of instances containing two distinct usages of the word.\n",
    "\n",
    "reference = list of instances containing two distinct usages of the word,\n",
    "with each having a similar usage with at least one instance in the query.\n",
    "\n",
    "Example:\n",
    "\n",
    "query = [\n",
    "  [\"i like books\", \"books\"],\n",
    "  [\"please book me a hotel\", \"book]\n",
    "]\n",
    "\n",
    "reference = [\n",
    "  [\"she read that book\", \"book\"],\n",
    "  [\"I will book those tickets shortly\", \"book]\n",
    "]]\n",
    "```\n",
    "\n",
    "The word you select should be different from the ones discussed in this file. Therefore, you cannot use: `face, book, bow, bank`. In all cases, the word being compared should be the same (different tense and number allowed: *books* vs. *book* or *book* vs *booked*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-B4FexHgYPo"
   },
   "outputs": [],
   "source": [
    "query = [[\"he beat the table with his hand\", \"beat\"], # Verb_1. strike (a person or an animal) repeatedly and violently so as to hurt or injure them, typically with an implement such as a club or whip\n",
    "        [\"He beat me at chess\", \"beat\"], # Verb_2. defeat (someone) in a game or other competitive situation\n",
    "        [\"the music changed to a funky disco beat\", \"beat\"]] # Noun. a main accent or rhythmic unit in music or poetry\n",
    "\n",
    "reference = [\n",
    "  [\"The piece has four beats to the bar\", \"beats\"], # n\n",
    "  [\"Their recent wins have proved they’re still the ones to beat\", \"beat\"], # v2\n",
    "  [\"he beat his own world record\", \"beat\"], # v2\n",
    "  [\"she beat her fists against the wood\", \"beat\"], # v1\n",
    "  [\"he heard the beat of a drum\", \"beat\"] #n\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Zq5btkDhR7"
   },
   "outputs": [],
   "source": [
    "model = cwe.CWE('bert-base-uncased')\n",
    "model_1 = cwe.CWE(\"roberta-base\")\n",
    "model_2 = cwe.CWE(\"roberta-large\")\n",
    "model_3 = cwe.CWE(\"bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cw0HOqEO6M-q"
   },
   "outputs": [],
   "source": [
    "reference_emb = model_1.extract_representation(reference)\n",
    "query_emb = model_1.extract_representation(query)\n",
    "\n",
    "reference_emb2 = model_1.extract_representation(reference, layer = 10)\n",
    "query_emb2 = model_1.extract_representation(query, layer = 10)\n",
    "\n",
    "# Model: Bert\n",
    "reference_emb3 = model.extract_representation(reference)\n",
    "query_emb3 = model.extract_representation(query)\n",
    "\n",
    "reference_emb4 = model_2.extract_representation(reference)\n",
    "query_emb4 = model_2.extract_representation(query)\n",
    "\n",
    "reference_emb5 = model_3.extract_representation(reference)\n",
    "query_emb5 = model_3.extract_representation(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L2-dqg1Q6NC6",
    "outputId": "65c03367-4b96-464f-a0a1-76f40cde4bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:RoBERTa, layer = 12 \n",
      " tensor([[0.8928, 0.8752, 0.9254, 0.9567, 0.8991],\n",
      "        [0.8606, 0.9054, 0.9513, 0.9092, 0.8763],\n",
      "        [0.8861, 0.8930, 0.8863, 0.8948, 0.9333]])\n",
      "model:RoBERTa, layer = 10 \n",
      " tensor([[0.8634, 0.8406, 0.9012, 0.9441, 0.8624],\n",
      "        [0.8425, 0.8785, 0.9296, 0.8810, 0.8296],\n",
      "        [0.8615, 0.8202, 0.8306, 0.8432, 0.8935]])\n",
      "model:BERT, layer = 12 \n",
      " tensor([[0.4661, 0.4273, 0.4799, 0.7304, 0.4620],\n",
      "        [0.3503, 0.5702, 0.6055, 0.4569, 0.3879],\n",
      "        [0.4892, 0.4833, 0.3816, 0.3605, 0.4991]])\n",
      "model:RoBERTa, layer = 24 \n",
      " tensor([[0.9774, 0.9685, 0.9865, 0.9905, 0.9754],\n",
      "        [0.9739, 0.9737, 0.9904, 0.9794, 0.9686],\n",
      "        [0.9789, 0.9696, 0.9746, 0.9703, 0.9808]])\n",
      "model:BERT, layer = 24 \n",
      " tensor([[0.4456, 0.4985, 0.5038, 0.8303, 0.5251],\n",
      "        [0.4829, 0.6406, 0.7208, 0.5317, 0.5447],\n",
      "        [0.5390, 0.5323, 0.4377, 0.3503, 0.6388]])\n"
     ]
    }
   ],
   "source": [
    "# Take the cosine of every query with every reference\n",
    "sims = cosine(query_emb, reference_emb)\n",
    "sims2 = cosine(query_emb2, reference_emb2)\n",
    "sims3 = cosine(query_emb3, reference_emb3)\n",
    "sims4 = cosine(query_emb4, reference_emb4)\n",
    "sims5 = cosine(query_emb5, reference_emb5)\n",
    "\n",
    "# explore the output:\n",
    "print('model:RoBERTa, layer = 12 \\n', sims)\n",
    "print('model:RoBERTa, layer = 10 \\n', sims2)\n",
    "print('model:BERT, layer = 12 \\n', sims3)\n",
    "print('model:RoBERTa, layer = 24 \\n', sims4)\n",
    "print('model:BERT, layer = 24 \\n', sims5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiHsFcbZ6NGm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AH-hCWIN6NIw",
    "outputId": "84ff48f1-aa4d-41c4-e3b3-d211842f8f21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['he beat the table with his hand', 'beat']\n",
      "Closest Reference: ['she beat her fists against the wood', 'beat'] \n",
      "\n",
      "Query: ['He beat me at chess', 'beat']\n",
      "Closest Reference: ['he beat his own world record', 'beat']\n",
      "\n",
      "Query: ['the music changed to a funky disco beat', 'beat']\n",
      "Closest Reference: ['he heard the beat of a drum', 'beat']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "closest1 = reference[sims[0].argmax().item()]\n",
    "print(f\"Query: {query[0]}\\nClosest Reference: {closest1} \\n\")\n",
    "\n",
    "closest2 = reference[sims[1].argmax().item()]\n",
    "print(f\"Query: {query[1]}\\nClosest Reference: {closest2}\\n\")\n",
    "\n",
    "closest3 = reference[sims[2].argmax().item()]\n",
    "print(f\"Query: {query[2]}\\nClosest Reference: {closest3}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiPWWRNGXjPj"
   },
   "source": [
    "# 1. In your write-up\n",
    "### 1.1 Write what word you chose.\n",
    "### & 1.2 The sentences you chose for the various senses of the word\n",
    "\n",
    "I find the word with two different verbs meaning most frequently used and one noun meaning commonly used in the Oxford Press dictionary.\n",
    "\n",
    "I chose the word 'beat' and The senses is the following\n",
    "- Verb_1) **Strike** (a person or an animal) repeatedly and violently so as to hurt or injure them, typically with an implement such as a club or whip\n",
    "> \"He `beat` the table with his hand.\" <br>\n",
    "> \"She `beat` her fists against the wood\"\n",
    "\n",
    "- Verb_2) **Defeat** (someone) in a game or other competitive situation\n",
    "> \"He `beat` me at chess.\" <br>\n",
    "> \"Their recent wins have proved they’re still the ones to `beat`\" <br>\n",
    "> \"He `beat` his own world record\"\n",
    "\n",
    "- Noun) A main **accent or rhythmic** unit in music or poetry\n",
    "> \"The music changed to a funky disco `beat`\" <br>\n",
    "> \"The piece has four `beat` to the bar\" <br>\n",
    "> \"He heard the `beat` of a drum\"\n",
    "\n",
    "### 1.3 What you found\n",
    "After I used one of models suggested, I wondered other model's perforamnce. Therefore, I ran the following models with different layers: <br>\n",
    ">model:RoBERTa, layer = 12 <br>\n",
    ">model:RoBERTa, layer = 10 <br>\n",
    ">model:BERT, layer = 12 <br>\n",
    ">model:RoBERTa, layer = 24 <br>\n",
    ">model:BERT, layer = 24 <br>\n",
    "\n",
    "The result is that, generally, RoBERTa showed better performance than BERT, and the more layers, the better performance.\n",
    "\n",
    "One of the most interesting points is that I naturally believe the cosine result will high if part of speech between query and reference is the same or the sense is the same. The final result shows well in every case, however, I could discover that it is only sometimes.\n",
    "\n",
    "For example, I see the similarity of \"beat\"(v2) in *He beat me at chess* with:\n",
    "1. first reference is 0.8606(N)\n",
    "2. second reference is 0.9054(v2)\n",
    "3. third reference is 0.9513(v2)\n",
    "4. fourth reference is 0.9092(v1)\n",
    "5. fifth reference is 0.8763(N) in the first model.\n",
    "\n",
    "Therefore, of course, the model printed the result that the closest reference is the third reference, but in more detail, I found that the fourth reference, which is more related to the first verb sense, shows a higher score than the second reference.\n",
    "\n",
    "Moreover, even in the same sense, I thought there was not a big gap over 0.00xx. However, I could see the most enormous gap is 0.08 in the second query of the Bert-large model, and the smallest gap is 0.0019 in the third query of the RoBERTa-large model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVmPVtPaZtcH"
   },
   "source": [
    "## Question 2, Different words, (related or same) meaning\n",
    "\n",
    "For your set of sentences in question 2, come up with new reference instances that include words that are related to only one of the sentences. For e.g., if I was comparing book (novel) vs book (reserving something):\n",
    "\n",
    "```\n",
    "query = [\n",
    "  [\"i like books\", \"books\"],\n",
    "  [\"please book me a hotel\", \"book]\n",
    "]\n",
    "\n",
    "references = [\n",
    "  [\"that was a good novel\", \"novel\"],\n",
    "  [\"i'd like to make a reservation\", \"reservation\"]\n",
    "]\n",
    "```\n",
    "\n",
    "here, `novel` should be closer to the first query than to the second, similarly, `reservation` should be closer to the second as opposed to the first.\n",
    "\n",
    "**Same as above, discuss the stimuli you created, and what you found.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQmPv2gFpUhA"
   },
   "outputs": [],
   "source": [
    "q2_query = [[\"they beat me with a stick and punched me\", \"beat\"], # Verb_1. strike (a person or an animal) repeatedly and violently so as to hurt or injure them, typically with an implement such as a club or whip\n",
    "        [\"he beat his own world record\", \"beat\"], # Verb_2. defeat (someone) in a game or other competitive situation\n",
    "        [\"the glissando begins on the second beat\", \"beat\"]] # Noun. a main accent or rhythmic unit in music or poetry\n",
    "\n",
    "q2_reference = [\n",
    "  [\"he made her count beats to the bar and clap the rhythm\", \"rhythm\"], # query_3\n",
    "  [\"she had still not quite admitted defeat\", \"defeat\"], # query_2\n",
    "  [\"they've conquered new markets in Japan\", \"conquered\"], # query_2\n",
    "  [\"a car hit the barrier\", \"hit\"], # query_1\n",
    "  [\"he raised his hand, as if to strike me\", \"strike\"], # query_1\n",
    "  [\"We walked at a fast tempo\", \"tempo\"], # query_3\n",
    "  [\"all she could hear was the pounding of her heart \", \"pounding\"] # query_3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOPsccaidoOp"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "q2_reference_emb = model_1.extract_representation(q2_reference)\n",
    "q2_query_emb = model_1.extract_representation(q2_query)\n",
    "\n",
    "q2_reference_emb2 = model_1.extract_representation(q2_reference, layer = 10)\n",
    "q2_query_emb2 = model_1.extract_representation(q2_query, layer = 10)\n",
    "\n",
    "# Model: Bert\n",
    "q2_reference_emb3 = model.extract_representation(q2_reference)\n",
    "q2_query_emb3 = model.extract_representation(q2_query)\n",
    "\n",
    "q2_reference_emb4 = model_2.extract_representation(q2_reference)\n",
    "q2_query_emb4 = model_2.extract_representation(q2_query)\n",
    "\n",
    "q2_reference_emb5 = model_3.extract_representation(q2_reference)\n",
    "q2_query_emb5 = model_3.extract_representation(q2_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pei2Ny6Nyua1",
    "outputId": "e80e5357-dabd-46f9-c501-088eb6f21912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:RoBERTa, layer = 12 \n",
      " tensor([[0.8345, 0.8232, 0.7949, 0.8815, 0.8875, 0.8074, 0.8255],\n",
      "        [0.8497, 0.8437, 0.8371, 0.8915, 0.8640, 0.8071, 0.8121],\n",
      "        [0.8865, 0.8417, 0.7975, 0.8689, 0.8589, 0.8334, 0.8094]])\n",
      "model:RoBERTa, layer = 10\n",
      " tensor([[0.8039, 0.8105, 0.8256, 0.8421, 0.8687, 0.7788, 0.8287],\n",
      "        [0.8139, 0.8416, 0.8797, 0.8630, 0.8361, 0.7972, 0.8228],\n",
      "        [0.8311, 0.8074, 0.7920, 0.7748, 0.7958, 0.8104, 0.7924]])\n",
      "model:BERT, layer = 12\n",
      " tensor([[0.2098, 0.1106, 0.3546, 0.4285, 0.4682, 0.2437, 0.3599],\n",
      "        [0.2358, 0.1770, 0.4544, 0.4355, 0.2972, 0.2309, 0.3746],\n",
      "        [0.6470, 0.4035, 0.2757, 0.2986, 0.2291, 0.5684, 0.3010]])\n",
      "model:RoBERTa, layer = 24\n",
      " tensor([[0.9397, 0.9475, 0.9441, 0.9612, 0.9385, 0.9145, 0.9075],\n",
      "        [0.9579, 0.9665, 0.9717, 0.9810, 0.9476, 0.9443, 0.9247],\n",
      "        [0.9675, 0.9534, 0.9568, 0.9628, 0.9345, 0.9435, 0.9229]])\n",
      "model:BERT, layer = 24\n",
      " tensor([[0.4674, 0.1582, 0.5238, 0.5196, 0.6433, 0.3106, 0.5279],\n",
      "        [0.4354, 0.1595, 0.5318, 0.4724, 0.4252, 0.2508, 0.4738],\n",
      "        [0.6822, 0.4693, 0.3220, 0.3256, 0.3718, 0.5423, 0.3946]])\n"
     ]
    }
   ],
   "source": [
    "# Take the cosine of every query with every reference\n",
    "q2_sims = cosine(q2_query_emb, q2_reference_emb)\n",
    "q2_sims2 = cosine(q2_query_emb2, q2_reference_emb2)\n",
    "q2_sims3 = cosine(q2_query_emb3, q2_reference_emb3)\n",
    "q2_sims4 = cosine(q2_query_emb4, q2_reference_emb4)\n",
    "q2_sims5 = cosine(q2_query_emb5, q2_reference_emb5)\n",
    "\n",
    "# explore the output:\n",
    "print('model:RoBERTa, layer = 12 \\n', q2_sims)\n",
    "print('model:RoBERTa, layer = 10\\n', q2_sims2)\n",
    "print('model:BERT, layer = 12\\n', q2_sims3)\n",
    "print('model:RoBERTa, layer = 24\\n', q2_sims4)\n",
    "print('model:BERT, layer = 24\\n', q2_sims5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULSFYcw0g48P"
   },
   "source": [
    "# model:RoBERTa, layer = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9kEyq7Lz5Y5",
    "outputId": "552d2c38-4eaa-41d4-b7d8-1c7ac0acdaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['they beat me with a stick and punched me', 'beat']\n",
      "Closest Reference: ['he raised his hand, as if to strike me', 'strike'] \n",
      "\n",
      "Query: ['he beat his own world record', 'beat']\n",
      "Closest Reference: ['a car hit the barrier', 'hit']\n",
      "\n",
      "Query: ['the glissando begins on the second beat', 'beat']\n",
      "Closest Reference: ['he made her count beats to the bar and clap the rhythm', 'rhythm']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2_closest1 = q2_reference[q2_sims[0].argmax().item()]\n",
    "print(f\"Query: {q2_query[0]}\\nClosest Reference: {q2_closest1} \\n\")\n",
    "\n",
    "q2_closest2 = q2_reference[q2_sims[1].argmax().item()]\n",
    "print(f\"Query: {q2_query[1]}\\nClosest Reference: {q2_closest2}\\n\")\n",
    "\n",
    "q2_closest3 = q2_reference[q2_sims[2].argmax().item()]\n",
    "print(f\"Query: {q2_query[2]}\\nClosest Reference: {q2_closest3}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35RcNghCg_UZ"
   },
   "source": [
    "# model:RoBERTa, layer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IkZnbv2JJFH0",
    "outputId": "064c03ea-87ba-48cf-d193-d3fff8283fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['they beat me with a stick and punched me', 'beat']\n",
      "Closest Reference: ['he raised his hand, as if to strike me', 'strike'] \n",
      "\n",
      "Query: ['he beat his own world record', 'beat']\n",
      "Closest Reference: [\"they've conquered new markets in Japan\", 'conquered']\n",
      "\n",
      "Query: ['the glissando begins on the second beat', 'beat']\n",
      "Closest Reference: ['he made her count beats to the bar and clap the rhythm', 'rhythm']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2_closest1 = q2_reference[q2_sims2[0].argmax().item()]\n",
    "print(f\"Query: {q2_query[0]}\\nClosest Reference: {q2_closest1} \\n\")\n",
    "\n",
    "q2_closest2 = q2_reference[q2_sims2[1].argmax().item()]\n",
    "print(f\"Query: {q2_query[1]}\\nClosest Reference: {q2_closest2}\\n\")\n",
    "\n",
    "q2_closest3 = q2_reference[q2_sims2[2].argmax().item()]\n",
    "print(f\"Query: {q2_query[2]}\\nClosest Reference: {q2_closest3}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHOlA-uGhC1A"
   },
   "source": [
    "# model:BERT, layer = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRchD9bYJIcX",
    "outputId": "af645956-2ee1-4b8f-c05c-0a8d26429d55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['they beat me with a stick and punched me', 'beat']\n",
      "Closest Reference: ['he raised his hand, as if to strike me', 'strike'] \n",
      "\n",
      "Query: ['he beat his own world record', 'beat']\n",
      "Closest Reference: [\"they've conquered new markets in Japan\", 'conquered']\n",
      "\n",
      "Query: ['the glissando begins on the second beat', 'beat']\n",
      "Closest Reference: ['he made her count beats to the bar and clap the rhythm', 'rhythm']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2_closest1 = q2_reference[q2_sims3[0].argmax().item()]\n",
    "print(f\"Query: {q2_query[0]}\\nClosest Reference: {q2_closest1} \\n\")\n",
    "\n",
    "q2_closest2 = q2_reference[q2_sims3[1].argmax().item()]\n",
    "print(f\"Query: {q2_query[1]}\\nClosest Reference: {q2_closest2}\\n\")\n",
    "\n",
    "q2_closest3 = q2_reference[q2_sims3[2].argmax().item()]\n",
    "print(f\"Query: {q2_query[2]}\\nClosest Reference: {q2_closest3}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWVCWS59hGNV"
   },
   "source": [
    "# model:RoBERTa, layer = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFHnlrsdJK7k",
    "outputId": "2dee1686-c84d-425f-e19d-fbaad0684078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['they beat me with a stick and punched me', 'beat']\n",
      "Closest Reference: ['a car hit the barrier', 'hit'] \n",
      "\n",
      "Query: ['he beat his own world record', 'beat']\n",
      "Closest Reference: ['a car hit the barrier', 'hit']\n",
      "\n",
      "Query: ['the glissando begins on the second beat', 'beat']\n",
      "Closest Reference: ['he made her count beats to the bar and clap the rhythm', 'rhythm']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2_closest1 = q2_reference[q2_sims4[0].argmax().item()]\n",
    "print(f\"Query: {q2_query[0]}\\nClosest Reference: {q2_closest1} \\n\")\n",
    "\n",
    "q2_closest2 = q2_reference[q2_sims4[1].argmax().item()]\n",
    "print(f\"Query: {q2_query[1]}\\nClosest Reference: {q2_closest2}\\n\")\n",
    "\n",
    "q2_closest3 = q2_reference[q2_sims4[2].argmax().item()]\n",
    "print(f\"Query: {q2_query[2]}\\nClosest Reference: {q2_closest3}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZeMwCqyhKHK"
   },
   "source": [
    "# model:BERT, layer = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2DNXg9cJTO8",
    "outputId": "63d8ed71-a69a-4702-8940-025a9ee81dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['they beat me with a stick and punched me', 'beat']\n",
      "Closest Reference: ['he raised his hand, as if to strike me', 'strike'] \n",
      "\n",
      "Query: ['he beat his own world record', 'beat']\n",
      "Closest Reference: [\"they've conquered new markets in Japan\", 'conquered']\n",
      "\n",
      "Query: ['the glissando begins on the second beat', 'beat']\n",
      "Closest Reference: ['he made her count beats to the bar and clap the rhythm', 'rhythm']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2_closest1 = q2_reference[q2_sims5[0].argmax().item()]\n",
    "print(f\"Query: {q2_query[0]}\\nClosest Reference: {q2_closest1} \\n\")\n",
    "\n",
    "q2_closest2 = q2_reference[q2_sims5[1].argmax().item()]\n",
    "print(f\"Query: {q2_query[1]}\\nClosest Reference: {q2_closest2}\\n\")\n",
    "\n",
    "q2_closest3 = q2_reference[q2_sims5[2].argmax().item()]\n",
    "print(f\"Query: {q2_query[2]}\\nClosest Reference: {q2_closest3}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EqNlLkEmF0U"
   },
   "outputs": [],
   "source": [
    "q2_query = [[\"they beat me with a stick and punched me\", \"beat\"], # Verb_1. strike (a person or an animal) repeatedly and violently so as to hurt or injure them, typically with an implement such as a club or whip\n",
    "        [\"he beat his own world record\", \"beat\"], # Verb_2. defeat (someone) in a game or other competitive situation\n",
    "        [\"the glissando begins on the second beat\", \"beat\"]] # Noun. a main accent or rhythmic unit in music or poetry\n",
    "\n",
    "q2_reference = [\n",
    "  [\"he made her count beats to the bar and clap the rhythm\", \"rhythm\"], # query_3\n",
    "  [\"she had still not quite admitted defeat\", \"defeat\"], # query_2\n",
    "  [\"they've conquered new markets in Japan\", \"conquered\"], # query_2\n",
    "  [\"a car hit the barrier\", \"hit\"], # query_1\n",
    "  [\"he raised his hand, as if to strike me\", \"strike\"], # query_1\n",
    "  [\"We walked at a fast tempo\", \"tempo\"], # query_3\n",
    "  [\"all she could hear was the pounding of her heart \", \"pounding\"] # query_3\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bltFoj5aEau"
   },
   "source": [
    "# 2. In your write-up\n",
    "### 2.1 Write what word you chose.& 2.2 The sentences you chose for the various senses of the word\n",
    "# `Beat`\n",
    "Based on the dictionary, I reference thesaurus in the Oxford press\n",
    "- Verb_1) Strike (a person or an animal) repeatedly and violently so as to hurt or injure them, typically with an implement such as a club or whip => `Strike`,\n",
    "`Hit`\n",
    "> \"He raised his hand, as if to `strike` me.\" <br>\n",
    "> \"A car `hit` the barrier\"\n",
    "\n",
    "- Verb_2) **Defeat** (someone) in a game or other competitive situation => `Defeat`,\n",
    "`Conquer`\n",
    "> \"She had still not quite admitted `defeat`.\" <br>\n",
    "> \"They've `conquered` new markets in Japan\" <br>\n",
    "\n",
    "- Noun) A main **accent or rhythmic** unit in music or poetry => `Rhythm`,\n",
    "`Tempo`, `Pounding`\n",
    "> \"He made her count beats to the bar and clap the `rhythm`\" <br>\n",
    "> \"We walked at a fast `tempo`\" <br>\n",
    "> \"All she could hear was the `pounding` of her heart\"\n",
    "\n",
    "\n",
    "### 2.3 What you found\n",
    "In this problem, I also found a very similar situation with the first write-up.\n",
    "\n",
    "RoBERTa performed better than BERT, and the more layers, the better. However, unlike first write-up, some models print wrongly.\n",
    "\n",
    "For example, I see the similarity of \"beat\"(V2) in *He beat me at chess* with:\n",
    "1. first reference is 0.8497(N / Rhythm)\n",
    "2. second reference is 0.8437(V2 / Defeat)\n",
    "3. third reference is 0.8371(V2 / Conquer)\n",
    "4. fourth reference is 0.8915(V1 / Hit)\n",
    "5. fifth reference is 0.9640(V1 / Strike)\n",
    "6. sixth reference is 0.8071 (N / Tempo)\n",
    "7. seventh reference is 0.8121 (N / Pounding) in the first model.\n",
    "\n",
    "Therefore, I expected the model to print out between the second and third reference, but as you can see, the V1 score is higher than the V2 score. Also, even if the model prints out the result I expected when I saw it in detail, there are some cases in which a reference is another part of speech and has another sense.\n",
    "\n",
    "Thus, I believe that even if the words have a similar sense in each query, I used different words, which caused the above results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD8BRcMQd6HP"
   },
   "source": [
    "## Question 3: Comparing cosine similarity across meanings(senses)\n",
    "\n",
    "We explore whether instances of same sense of a word are more similar than different sense instances of a word. We hypothesize that the former is the case, but let's find out!\n",
    "\n",
    "e.g. The word *'book'* has two senses (*novel* and *reserving something*) discussed in the previous questions. But are same sense instances of the word book (*novel* vs *novel*) more similar on average than different sense instances of the word book (*novel* vs *reserving something*)?\n",
    "\n",
    "We specify two word-sense specific cosine relatedness measures, which you can use to perform comparisons.\n",
    "\n",
    "**Same Sense similarity:** Average cosine similarity between same sense (meaning) instances of a word\n",
    "\n",
    "\\begin{equation}\n",
    "\\operatorname{SenSim}_{\\ell}\\left(w_{s}\\right)=\\frac{1}{m} \\sum_{j} \\sum_{k \\neq j} \\cos \\left(v_{\\ell}\\left(w_{s_{j}}\\right), v_{\\ell}\\left(w_{s_{k}}\\right)\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "**Inter Sense similarity:** Average cosine similarity between different sense (meaning) instances of a word\n",
    "\n",
    "\\begin{equation}\n",
    "\\operatorname{InterSim}_{\\ell}(w)=\\mathbb{E}_{a, b \\in S}\\left[\\frac{1}{m n} \\sum_{j=1}^{m} \\sum_{i=1}^{n} \\cos \\left(v_{\\ell}\\left(w_{a_{i}}\\right), v_{\\ell}\\left(w_{b_{j}}\\right)\\right)\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJF0eCzaLeF2"
   },
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHvcNjYJGqtS"
   },
   "source": [
    "Now it's your turn!\n",
    "\n",
    "Select three polysemous words (same word, multiple meanings) and perform same sense and inter sense similarity analysis like the examples given above. Compare results across at least two senses of each word and report your findings.\n",
    "\n",
    "The words you select should be different from the ones discussed in this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_ApKTzxBK8v"
   },
   "source": [
    "# 1. Same Sense Similarity\n",
    "\n",
    "*query: beat (defeat (someone) in a game or other competitive situation)*\n",
    "\n",
    "references: beat: defeat (someone) in a game or other competitive situation\n",
    "  - a. overcome (a problem or disease)\n",
    "  - b. do or be better than (a record or score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gq1yhZkHBLKu"
   },
   "outputs": [],
   "source": [
    "query_same_sense = [\n",
    "         [\"He beat me at chess\", \"beat\"], # defeat (someone) in a game or other competitive situation\n",
    "        ]\n",
    "\n",
    "reference_same_sense = [\n",
    "             [\"the president said beating violent crime was his first priority\", \"beating\"], # overcome (a problem or disease)\n",
    "             [\"he beat his own world record\", \"beat\"], # do or be better than (a record or score)\n",
    "             [\"The young prodigy beat the odds and defeated the experienced grandmaster in a nail-biting game of Go\",\n",
    "              \"beat\"], # defeat (someone) in a game or other competitive situation\n",
    "             [\"Sarah used a brilliant strategy to beat her opponent and secure the championship\", \"beat\"], # defeat (someone) in a game or other competitive situation\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-P-VmtwhN7NB",
    "outputId": "d757f06d-d50d-45f3-fbce-43f70aa8f9f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  beat (defeat (someone) in a game or other competitive situation)\n",
      "reference:  beat (defeat / overcome / do or be better than)\n",
      "Same sense similarity: 0.902\n",
      "Same sense similarity: 0.976\n",
      "Same sense similarity: 0.651\n"
     ]
    }
   ],
   "source": [
    "q3_1_reference_emb = model_1.extract_representation(reference_same_sense, layer = 10)\n",
    "q3_1_query_emb = model_1.extract_representation(query_same_sense, layer = 10)\n",
    "\n",
    "q3_1_reference_emb_1 = model_2.extract_representation(reference_same_sense)\n",
    "q3_1_query_emb_1 = model_2.extract_representation(query_same_sense)\n",
    "\n",
    "q3_1_reference_emb_2 = model_3.extract_representation(reference_same_sense)\n",
    "q3_1_query_emb_2 = model_3.extract_representation(query_same_sense)\n",
    "\n",
    "\n",
    "# Take the cosine of every query with every reference\n",
    "q3_1_sims = cosine(q3_1_query_emb, q3_1_reference_emb)\n",
    "q3_1_sims_1 = cosine(q3_1_query_emb_1, q3_1_reference_emb_1)\n",
    "q3_1_sims_2 = cosine(q3_1_query_emb_2, q3_1_reference_emb_2)\n",
    "\n",
    "# explore the output:\n",
    "print(\"query:  beat (defeat (someone) in a game or other competitive situation)\")\n",
    "print(\"reference:  beat (defeat / overcome / do or be better than)\")\n",
    "print('Same sense similarity:', round(torch.mean(q3_1_sims).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_1_sims_1).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_1_sims_2).item(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvGZxkNcrffy"
   },
   "source": [
    "# 2. Same Sense Similarity\n",
    "\n",
    "query: Rock: move gently to and fro or from side to side\n",
    "\n",
    "references: Rock: move gently to and fro or from side to side\n",
    " - a. shake or cause to shake or vibrate, especially because of an impact earthquake, or explosion\n",
    " - b. cause great shock or distress to (someone or something), especially so as to weaken or destabilize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuTQJsFhrr6V"
   },
   "outputs": [],
   "source": [
    "query2_same_sense = [\n",
    "         [\"she rocked the baby in her arms\", \"rocked\"], # move gently to and fro or from side to side\n",
    "        ]\n",
    "\n",
    "reference2_same_sense = [\n",
    "             [\"the vase rocked back and forth on its base\", \"rocked\"], # move gently to and fro or from side to side\n",
    "             [\"minutes later a second blast rocked the city\", \"rocked\"], # shake or cause to shake or vibrate\n",
    "             [\"The unexpected economic downturn has the potential to rock the stability of the financial markets\",\n",
    "              \"rock\"], # cause great shock or distress to (someone or something)\n",
    "             [\"The earthquake that hit the region not only caused physical damage but also emotionally rocked the local community.\", \"rocked\"], # cause great shock or distress to (someone or something)\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQXplvQsrsDH",
    "outputId": "b54d5772-97eb-4d1f-957b-f3eb6f1e64e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  Rock: move gently to and fro or from side to side\n",
      "reference:  Rock (move / shake / cause great shock or distress)\n",
      "Same sense similarity: 0.873\n",
      "Same sense similarity: 0.981\n",
      "Same sense similarity: 0.621\n"
     ]
    }
   ],
   "source": [
    "q3_1_reference_emb2 = model_1.extract_representation(reference2_same_sense, layer = 10)\n",
    "q3_1_query_emb2 = model_1.extract_representation(query2_same_sense, layer = 10)\n",
    "\n",
    "q3_1_reference_emb2_1 = model_2.extract_representation(reference2_same_sense)\n",
    "q3_1_query_emb2_1 = model_2.extract_representation(query2_same_sense)\n",
    "\n",
    "q3_1_reference_emb2_2 = model_3.extract_representation(reference2_same_sense)\n",
    "q3_1_query_emb2_2 = model_3.extract_representation(query2_same_sense)\n",
    "\n",
    "\n",
    "# Take the cosine of every query with every reference\n",
    "q3_1_sims2 = cosine(q3_1_query_emb2, q3_1_reference_emb2)\n",
    "q3_1_sims2_1 = cosine(q3_1_query_emb2_1, q3_1_reference_emb2_1)\n",
    "q3_1_sims2_2 = cosine(q3_1_query_emb2_2, q3_1_reference_emb2_2)\n",
    "\n",
    "# explore the output:\n",
    "print(\"query:  Rock: move gently to and fro or from side to side\")\n",
    "print(\"reference:  Rock (move / shake / cause great shock or distress)\")\n",
    "print('Same sense similarity:', round(torch.mean(q3_1_sims2).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_1_sims2_1).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_1_sims2_2).item(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUIcIUo9rtQs"
   },
   "source": [
    "# 3. Same Sense Similarity\n",
    "\n",
    "query: Rest: cease work or movement in order to relax, sleep, or recover strength\n",
    "\n",
    "references: Rest: cease work or movement in order to relax, sleep, or recover strength\n",
    " - a. allow to be inactive in order to regain strength or health\n",
    " - b. (of a body) lie buried\n",
    " - c. used euphemistically by actors to indicate that they are out of work\n",
    " - d. leave (a player) out of a team temporarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snWd-B3esDv4"
   },
   "outputs": [],
   "source": [
    "query3_same_sense = [\n",
    "         [\"he needed to rest after the feverish activity\", \"rest\"], # move gently to and fro or from side to side\n",
    "        ]\n",
    "\n",
    "reference3_same_sense = [\n",
    "             [\" going to rest up before travelling to England\", \"rest\"], # move gently to and fro or from side to side\n",
    "             [\"her friend read to her while she rested her eyes\", \"rested\"], # allow to be inactive in order to regain strength or health\n",
    "             [\"the king's body rested in his tomb\", \"rested\"], # (of a body) lie buried\n",
    "             [\"she was an actress but doing domestic work while she was resting.\", \"resting\"], # cause great shock or distress to (someone or something)\n",
    "             [\"both men were rested for the cup final\", \"rested\"]] # leave (a player) out of a team temporarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMPJF2YQsD1I",
    "outputId": "725ffa2d-c2c5-4cb3-f0bc-d322259fdb44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  Rest: cease work or movement in order to relax, sleep, or recover strength\n",
      "reference:  Rest ( cease / allow to be inactive / lie buried / used euphemistically / leave out of a team )\n",
      "Same sense similarity: 0.895\n",
      "Same sense similarity: 0.964\n",
      "Same sense similarity: 0.679\n"
     ]
    }
   ],
   "source": [
    "q3_1_reference_emb3 = model_1.extract_representation(reference3_same_sense, layer = 10)\n",
    "q3_1_query_emb3 = model_1.extract_representation(query3_same_sense, layer = 10)\n",
    "\n",
    "q3_1_reference_emb3_1 = model_2.extract_representation(reference3_same_sense)\n",
    "q3_1_query_emb3_1 = model_2.extract_representation(query3_same_sense)\n",
    "\n",
    "q3_1_reference_emb3_2 = model_3.extract_representation(reference3_same_sense)\n",
    "q3_1_query_emb3_2 = model_3.extract_representation(query3_same_sense)\n",
    "\n",
    "\n",
    "# Take the cosine of every query with every reference\n",
    "q3_1_sims3 = cosine(q3_1_query_emb3, q3_1_reference_emb3)\n",
    "q3_1_sims3_1 = cosine(q3_1_query_emb3_1, q3_1_reference_emb3_1)\n",
    "q3_1_sims3_2 = cosine(q3_1_query_emb3_2, q3_1_reference_emb3_2)\n",
    "\n",
    "# explore the output:\n",
    "print(\"query:  Rest: cease work or movement in order to relax, sleep, or recover strength\")\n",
    "print(\"reference:  Rest ( cease / allow to be inactive / lie buried / used euphemistically / leave out of a team )\")\n",
    "print('Same sense similarity:', round(torch.mean(q3_1_sims3).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_1_sims3_1).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_1_sims3_2).item(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDSndnVBP5Kd"
   },
   "source": [
    "# 1. Inter Sense Similarity\n",
    "\n",
    "*query: Beat: defeat (someone) in a game or other competitive situation*\n",
    "\n",
    "*references: Beat: a main accent or rhythmic unit in music or poetry*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCkwG1ANSRqP"
   },
   "outputs": [],
   "source": [
    "query_different_sense = [[\"the swimmer finally beat the world record in the 100-meter freestyle event\", \"beat\"], # Verb_2. defeat (someone) in a game or other competitive situation\n",
    "                         ]\n",
    "\n",
    "reference_different_sense = [\n",
    "  [\"The drummer set the tempo with a steady beat that echoed throughout the concert hall.\", \"beat\"], # rhythmic unit\n",
    "  [\"The music had a catchy beat that had everyone dancing on the dance floor.\", \"beat\"], # rhythmic unit\n",
    "  [\"The conductor directed the orchestra to emphasize the strong beat in the musical composition\", \"beat\"], # rhythmic unit\n",
    "  [\"he made her count beats to the bar and clap the rhythm\", \"beats\"], # rhythmic unit\n",
    "  [\"all she could hear was the beat of her heart \", \"beat\"] # rhythmic unit\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRj56Pg6l1hU",
    "outputId": "cac9f9f3-d11e-49a4-d902-ec7e4a128dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same sense similarity: 0.831\n",
      "Same sense similarity: 0.965\n",
      "Same sense similarity: 0.486\n"
     ]
    }
   ],
   "source": [
    "q3_2_reference_emb = model_1.extract_representation(reference_different_sense, layer = 10)\n",
    "q3_2_query_emb = model_1.extract_representation(query_different_sense, layer = 10)\n",
    "\n",
    "q3_2_reference_emb_1 = model_2.extract_representation(reference_different_sense)\n",
    "q3_2_query_emb_1 = model_2.extract_representation(query_different_sense)\n",
    "\n",
    "q3_2_reference_emb_2 = model_3.extract_representation(reference_different_sense)\n",
    "q3_2_query_emb_2 = model_3.extract_representation(query_different_sense)\n",
    "\n",
    "# Take the cosine of every query with every reference\n",
    "q3_2_sims2 = cosine(q3_2_query_emb, q3_2_reference_emb)\n",
    "q3_2_sims_1 = cosine(q3_2_query_emb_1, q3_2_reference_emb_1)\n",
    "q3_2_sims_2 = cosine(q3_2_query_emb_2, q3_2_reference_emb_2)\n",
    "\n",
    "# explore the output:\n",
    "print(\"query: beat (defeat (someone) in a game or other competitive situation)\")\n",
    "print(\"reference: beat (a main accent or rhythmic unit in music or poetry)\")\n",
    "print('Same sense similarity:', round(torch.mean(q3_2_sims2).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_2_sims_1).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_2_sims_2).item(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCDqMqdN15YV"
   },
   "source": [
    "# 2. Inter Sense Similarity\n",
    "\n",
    "query: Rock: move gently to and fro or from side to side\n",
    "\n",
    "references: Rock: he solid mineral material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugtuVJ-u157n"
   },
   "outputs": [],
   "source": [
    "query_different_sense2 = [[\"she rocked the baby in her arms\", \"rocked\"], #\n",
    "                         ]\n",
    "\n",
    "reference_different_sense2 = [\n",
    "  [\"the beds of rock are slightly tilted.\", \"rock\"],\n",
    "  [\"There are dangerous rocks around the island.\", \"rocks\"],\n",
    "  [\"This bread is (as) hard as a rock\", \"rock\"], #\n",
    "  [\"Moss can grow on bare rock\", \"rock\"], #\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWlJbmCFlx-I",
    "outputId": "d3dc2dbd-65bf-4000-83f4-ea7331e253cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same sense similarity: 0.802\n",
      "Same sense similarity: 0.975\n",
      "Same sense similarity: 0.506\n"
     ]
    }
   ],
   "source": [
    "q3_2_reference_emb2 = model_1.extract_representation(reference_different_sense2, layer = 10)\n",
    "q3_2_query_emb2 = model_1.extract_representation(query_different_sense2, layer = 10)\n",
    "\n",
    "q3_2_reference_emb2_1 = model_2.extract_representation(reference_different_sense2)\n",
    "q3_2_query_emb2_1 = model_2.extract_representation(query_different_sense2)\n",
    "\n",
    "q3_2_reference_emb2_2 = model_3.extract_representation(reference_different_sense2)\n",
    "q3_2_query_emb2_2 = model_3.extract_representation(query_different_sense2)\n",
    "\n",
    "# Take the cosine of every query with every reference\n",
    "q3_2_sims2 = cosine(q3_2_query_emb2, q3_2_reference_emb2)\n",
    "q3_2_sims2_1 = cosine(q3_2_query_emb2_1, q3_2_reference_emb2_1)\n",
    "q3_2_sims2_2 = cosine(q3_2_query_emb2_2, q3_2_reference_emb2_2)\n",
    "\n",
    "# explore the output:\n",
    "\n",
    "print('Same sense similarity:', round(torch.mean(q3_2_sims2).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_2_sims2_1).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_2_sims2_2).item(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1BHry8q16fa"
   },
   "source": [
    "# 3. Inter Sense Similarity\n",
    "query: Rest: cease work or movement in order to relax, sleep, or recover strength\n",
    "\n",
    "references: Rest: the remaining part of something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pr6MSYEH16pU"
   },
   "outputs": [],
   "source": [
    "query_different_sense3 = [[\"he needed to rest after the feverish activity\", \"rest\"], #\n",
    "                         ]\n",
    "\n",
    "reference_different_sense3 = [\n",
    "  [\"What do you want to do for the rest of your life?\", \"rest\"],\n",
    "  [\"I'll tell you the rest tomorrow night.\", \"rest\"],\n",
    "  [\"The rest of us were experienced skiers\", \"rest\"],\n",
    "  [\"We finished the rest of the cake.\", \"rest\"]\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2y_HCp-16uh",
    "outputId": "a62c57a3-8773-454b-c6fc-4bc5f08f6bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same sense similarity: 0.781\n",
      "Same sense similarity: 0.931\n",
      "Same sense similarity: 0.547\n"
     ]
    }
   ],
   "source": [
    "q3_2_reference_emb3 = model_1.extract_representation(reference_different_sense3, layer = 10)\n",
    "q3_2_query_emb3 = model_1.extract_representation(query_different_sense3, layer = 10)\n",
    "\n",
    "q3_2_reference_emb3_1 = model_2.extract_representation(reference_different_sense3)\n",
    "q3_2_query_emb3_1 = model_2.extract_representation(query_different_sense3)\n",
    "\n",
    "q3_2_reference_emb3_2 = model_3.extract_representation(reference_different_sense3)\n",
    "q3_2_query_emb3_2 = model_3.extract_representation(query_different_sense3)\n",
    "\n",
    "# Take the cosine of every query with every reference\n",
    "q3_2_sims3 = cosine(q3_2_query_emb3, q3_2_reference_emb3)\n",
    "q3_2_sims3_1 = cosine(q3_2_query_emb3_1, q3_2_reference_emb3_1)\n",
    "q3_2_sims3_2 = cosine(q3_2_query_emb3_2, q3_2_reference_emb3_2)\n",
    "\n",
    "# explore the output:\n",
    "\n",
    "print('Same sense similarity:', round(torch.mean(q3_2_sims3).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_2_sims3_1).item(),3))\n",
    "print('Same sense similarity:', round(torch.mean(q3_2_sims3_2).item(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zw15ZsVW9kU"
   },
   "source": [
    "# 3. In your write-up\n",
    "### 3.1 Write what word you chose. & 3.2 The sentences you chose for the different senses of the word\n",
    "\n",
    "# Same sense\n",
    "## beat: defeat (someone) in a game or other competitive situation\n",
    "  - a. overcome (a problem or disease)\n",
    "  - b. do or be better than (a record or score)\n",
    "\n",
    "## Rock: move gently to and fro or from side to side\n",
    " - a. shake or cause to shake or vibrate, especially because of an impact earthquake, or explosion\n",
    " - b. cause great shock or distress to (someone or something), especially so as to weaken or destabilize\n",
    "\n",
    "## Rest: cease work or movement in order to relax, sleep, or recover strength\n",
    " - a. allow to be inactive in order to regain strength or health\n",
    " - b. (of a body) lie buried\n",
    " - c. used euphemistically by actors to indicate that they are out of work\n",
    " - d. leave (a player) out of a team temporarily\n",
    "\n",
    "# Inter sense\n",
    "\n",
    "Beat:defeat (someone) in a game or other competitive situation <br>\n",
    "Beat: a main accent or rhythmic unit in music or poetry\n",
    "\n",
    "Rock: move gently to and fro or from side to side <br>\n",
    "Rock: he solid mineral material\n",
    "\n",
    "Rest: cease work or movement in order to relax, sleep, or recover strength <br>\n",
    "Rest: the remaining part of something\n",
    "\n",
    "### 3.3 The differences you found in same sense and inter sense similarity across words.\n",
    "\n",
    "I used only three models:\n",
    ">model:RoBERTa, layer = 10 <br>\n",
    ">model:RoBERTa, layer = 24 <br>\n",
    ">model:BERT, layer = 24 <br>\n",
    "\n",
    "There is no significant reversal related to the performance of models.\n",
    "\n",
    "In inter sense, I picked each verb and noun.\n",
    "\n",
    "**Optional question:** *Do you think word sense diversity plays a role in the gap between same sense and inter sense similarity values?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8bOdL455mF6"
   },
   "source": [
    "## Question 4: Your turn!\n",
    "\n",
    "Ask your own question! It could be about comparing the above results on different models, or different layers of the same model. Feel free to explore!\n",
    "\n",
    "**Write about your analysis, what choices you made, and the results you got, and the conclusions you derived.**\n",
    "\n",
    "# I reported each write-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcgB3l--mukI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6BgI-I7yNthx",
    "9o_-SqH7RCpx",
    "6eD2tDV03wkz"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
