{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cda048d-84da-4c00-8be9-80c2f5040e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "from nltk.corpus import cmudict\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from difflib import SequenceMatcher\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfa7247-fc6d-446f-a95a-199bf4d70f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\LG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# CMU Dictionary\n",
    "nltk.download('cmudict')\n",
    "cmu = nltk.corpus.cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a907443-47ea-416b-8038-4e4602394e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a34490-75e3-4937-b11b-da227be2923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01c19887-62f2-425a-a340-1a35dfac2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update('.', '?', '-', '\\'', '\\:', ',', '!', '<', '>', '\\\"', '/', '(', ')',\n",
    "                  '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 's', 't', 're', 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c072bc7d-c73b-40c5-92f3-4c64e9b7b290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'was', 'jumping', 'over', 'the', 'lazy', 'dog', '.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "text = \"The quick brown fox was jumping over the lazy dog.\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18be89d-cbde-49e8-b318-23710c254324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10557d10-2c6b-4e58-86ba-bb51fe8cf0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove Punctuation and Tokenize Text\n",
    "def tokenize_text(text):\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    words = tokenizer.tokenize(text)\n",
    "    \n",
    "    original_sentences = []\n",
    "    original_sentence = []\n",
    "    \n",
    "    vocab = w2v_model.index_to_key\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        original_sentence.append(words[i].lower())\n",
    "    original_sentences.append(original_sentence)\n",
    "\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if words[i].lower() not in stop_words and words[i].lower() in vocab:\n",
    "            sentence.append(words[i].lower())\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "    print('original_sentences',original_sentences[0])\n",
    "    print(\" \")\n",
    "    print('sentences',sentences[0])\n",
    "    \n",
    "    return sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c704970d-5741-416d-8e6e-7512ab5abeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_sentences ['the', 'quick', 'brown', 'fox', 'was', 'jumping', 'over', 'the', 'lazy', 'dog']\n",
      " \n",
      "sentences ['quick', 'brown', 'fox', 'jumping', 'lazy', 'dog']\n",
      "Homophones for \"quick\": ['cwik', 'kwik', 'quick', 'quik']\n",
      "Homophones for \"brown\": ['brown', 'browne']\n",
      "Homophones for \"fox\": ['fox', 'foxx']\n",
      "Homophones for \"jumping\": ['jumping']\n",
      "Homophones for \"lazy\": ['lazy']\n",
      "Homophones for \"dog\": ['dog']\n",
      "Pun Keywords: []\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Find Homophones\n",
    "def find_homophones(word, cmu_dict):\n",
    "    homophones = [key for key, value in cmu_dict.items() if value == cmu_dict[word]]\n",
    "    return homophones\n",
    "\n",
    "# Step 4: Phonetic Analysis\n",
    "def phonetic_analysis(word, cmu_dict):\n",
    "    return cmu_dict[word]\n",
    "\n",
    "# Step 5: Find Pun Keywords\n",
    "def find_pun_keywords(words):\n",
    "    # Implement your pun keyword detection logic here\n",
    "    return []\n",
    "\n",
    "# Step 6: Search for Phrases\n",
    "def search_phrases(word, phrases, error_margin):\n",
    "    similar_phrases = []\n",
    "    for phrase in phrases:\n",
    "        similarity = SequenceMatcher(None, word, phrase).ratio()\n",
    "        if similarity >= (1 - error_margin):\n",
    "            similar_phrases.append(phrase)\n",
    "    return similar_phrases\n",
    "\n",
    "# Example Usage\n",
    "text = \"The quick brown fox was jumping over the lazy dog.\"\n",
    "text2 = \"The boating store had its best sail ever.\"\n",
    "text = remove_punctuation(text)\n",
    "words = tokenize_text(text)\n",
    "\n",
    "\n",
    "for word in words:\n",
    "    homophones = find_homophones(word, cmu)\n",
    "    if homophones:\n",
    "        print(f'Homophones for \"{word}\": {homophones}')\n",
    "    else:\n",
    "        phonetics = phonetic_analysis(word, cmu)\n",
    "        print(f'Phonetics for \"{word}\": {phonetics}')\n",
    "\n",
    "# Find Pun Keywords\n",
    "pun_keywords = find_pun_keywords(words)\n",
    "print(f'Pun Keywords: {pun_keywords}')\n",
    "\n",
    "# Search for Phrases\n",
    "phrases = [\"The quick brown fox\", \"The lazy dog\", \"jumps over\", \"was jumping\"]\n",
    "error_margin = 0.2\n",
    "for word in words:\n",
    "    similar_phrases = search_phrases(word, phrases, error_margin)\n",
    "    if similar_phrases:\n",
    "        print(f'Similar Phrases for \"{word}\": {similar_phrases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f35d986-5d0f-4465-a031-c48108b29ff0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'The boating store had its best sail ever.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-aea1a350f3c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfind_homophones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The boating store had its best sail ever.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-e7327dbc0a77>\u001b[0m in \u001b[0;36mfind_homophones\u001b[1;34m(word, cmu_dict)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Step 3: Find Homophones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_homophones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mhomophones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhomophones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-e7327dbc0a77>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Step 3: Find Homophones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_homophones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mhomophones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhomophones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'The boating store had its best sail ever.'"
     ]
    }
   ],
   "source": [
    "find_homophones('The boating store had its best sail ever.', cmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e24f041-506f-4a94-9b12-aca3759c203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'boating', 'store', 'had', 'its', 'best', 'sail', 'ever', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenize_text('The boating store had its best sail ever.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e4521f6-0b4e-4582-9dde-712dbcf99267",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-ec0d181367f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cbff646-dfc1-409e-957e-b5b33448ea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_sentences ['the', 'boating', 'store', 'had', 'its', 'best', 'sail', 'ever']\n",
      " \n",
      "sentences ['boating', 'store', 'best', 'sail', 'ever']\n",
      "Homophones for \"boating\": ['boating']\n",
      "Homophones for \"store\": ['stoehr', 'stohr', 'store', 'storr']\n",
      "Homophones for \"best\": ['best', 'beste']\n",
      "Homophones for \"sail\": ['sail', 'sale', 'salle', 'sayle']\n",
      "Homophones for \"ever\": ['ever']\n"
     ]
    }
   ],
   "source": [
    "text2 = \"The boating store had its best sail ever.\"\n",
    "\n",
    "words = tokenize_text(text2)\n",
    "\n",
    "for word in words:\n",
    "#     print('word', word)\n",
    "    homophones = find_homophones(word, cmu)\n",
    "    if homophones:\n",
    "        print(f'Homophones for \"{word}\": {homophones}')\n",
    "    else:\n",
    "        phonetics = phonetic_analysis(word, cmu)\n",
    "        print(f'Phonetics for \"{word}\": {phonetics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44055743-164d-455b-9c9a-0eaacd3cb065",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'The boating store had its best sail ever'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-969790bd6d2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfind_homophones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The boating store had its best sail ever'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-604defc53846>\u001b[0m in \u001b[0;36mfind_homophones\u001b[1;34m(word, cmu_dict)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Step 3: Find Homophones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_homophones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mhomophones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhomophones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-604defc53846>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Step 3: Find Homophones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_homophones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mhomophones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcmu_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhomophones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'The boating store had its best sail ever'"
     ]
    }
   ],
   "source": [
    "find_homophones('The boating store had its best sail ever',cmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eacce5-ca8a-4b75-a84c-0b0521552b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
