{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6a9nbSgAUE5"
   },
   "source": [
    "# Yoonhyuck Woo, Rishika Thorat / Purdue University_Computer and Information Technology\n",
    "# Final Project Title: Movie Recommendation System\n",
    "# Professor: Jin Wei-Kocsis, Ph.D.\n",
    "\n",
    "- Reference: ***https://medium.com/@AMustafa4983/sentiment-analysis-on-imdb-movie-reviews-a-beginners-guide-d5136ec74e56***\n",
    "-Reference: ***https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recommender/neural_collaborative_filtering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nvr6d48l-jdM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Flatten, Dropout, Dense, Input, Dot\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tx1f_w0EVxId",
    "outputId": "512a8bc3-d5b2-4c3b-d0c9-d48dcba9d55a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "CqGgTZU9xAo3",
    "outputId": "5792587e-b346-413a-e011-2777db6882be"
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ce08ddae0a7d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdJCdM8UryYZ"
   },
   "source": [
    "# IMDB DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "N5rGOnwq_pUp"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "imdb_df = pd.read_csv('/content/drive/MyDrive/IMDB_Dataset.csv') # put your path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "twgZqah--olU"
   },
   "outputs": [],
   "source": [
    "imdb_df['sentiment']=imdb_df['sentiment'].replace({'positive':1, 'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFfdPDmk_va3",
    "outputId": "5695373a-c606-4a01-d306-4b3caa75f9af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for bias\n",
    "imdb_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRLfECkI_95w"
   },
   "source": [
    "# Function1: Removing Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "X1FS05Gr_8Hf"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = text.split()\n",
    "    filtered_sentence = ''\n",
    "\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sentence = filtered_sentence + word + ' '\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Yh6fL7kBAAJo"
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    # get rid of urls\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    # get rid of non words and extra spaces\n",
    "    text = re.sub('\\\\W', ' ', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub('^ ', '', text)\n",
    "    text = re.sub(' $', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eNkO72BIAf3d"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    words = text.split()\n",
    "    filtered_sentence = ''\n",
    "    for word in words:\n",
    "        word = word.translate(table)\n",
    "        filtered_sentence = filtered_sentence + word + ' '\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q2bRIg5yAjlN"
   },
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    words = text.split()\n",
    "    filtered_sentence = ''\n",
    "    for word in words:\n",
    "        word = ps.stem(word)\n",
    "        filtered_sentence = filtered_sentence + word + ' '\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M2TjnX_QAmNs"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(',',' , ')\n",
    "    text = text.replace('.',' . ')\n",
    "    text = text.replace('/',' / ')\n",
    "    text = text.replace('@',' @ ')\n",
    "    text = text.replace('#',' # ')\n",
    "    text = text.replace('?',' ? ')\n",
    "    text = normalize_text(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stemming(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCMDBj-MgrNu",
    "outputId": "3da636c1-7829-40e0-b6b4-a2e148a54756"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-ecdc8ccc4d89>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imdb_df[\"review\"][i] = clean_text(imdb_df[\"review\"][i])\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "  for i in range (len(imdb_df[\"review\"])):\n",
    "    imdb_df[\"review\"][i] = clean_text(imdb_df[\"review\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wNoh1iB4Arn7"
   },
   "outputs": [],
   "source": [
    "X = imdb_df[\"review\"]\n",
    "y = imdb_df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLc6naKWAu2M"
   },
   "source": [
    "# Tokenization and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "syUcaZMiAvj-"
   },
   "outputs": [],
   "source": [
    "# important properties\n",
    "vocab_size = 10000\n",
    "max_length = 50\n",
    "\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ccx4p4dKAzCB"
   },
   "outputs": [],
   "source": [
    "# Define tokenizer and fit on texts\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NnR2ZHmeA1Gx"
   },
   "outputs": [],
   "source": [
    "# Let's Tokenize and pad texts\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_length,\n",
    "                         padding=padding_type,\n",
    "                         truncating=trunc_type)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length,\n",
    "                         padding=padding_type,\n",
    "                         truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "v2m6sLY9A3hZ"
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(Embedding(vocab_size, 64, input_length=max_length))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))  # Add dropout regularization\n",
    "\n",
    "    model.add(LSTM(32, return_sequences=True))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))  # Add dropout regularization\n",
    "\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))  # Add dropout regularization\n",
    "\n",
    "    # model.add(Dense(2, activation='softmax'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6euewxSDfxgh"
   },
   "source": [
    "# Movie Recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Fb50gdYXfvs3"
   },
   "outputs": [],
   "source": [
    "def CF_model(input_data):\n",
    "  data = input_data\n",
    "  user_embed_dim = 32\n",
    "  movie_embed_dim = 32\n",
    "\n",
    "  # User and Movie Input Layers\n",
    "  user_input = Input(shape=(1,), name='user_input')\n",
    "  movie_input = Input(shape=(1,), name='movie_input')\n",
    "\n",
    "  # User and Movie Embedding Layers\n",
    "  user_embedding = Embedding(input_dim=data['userId'].max()+1, output_dim=user_embed_dim, input_length=1)(user_input)\n",
    "  movie_embedding = Embedding(input_dim=data['movieId'].max()+1, output_dim=movie_embed_dim, input_length=1)(movie_input)\n",
    "\n",
    "  # Flatten the Embedding Layers\n",
    "  user_flat = Flatten()(user_embedding)\n",
    "  movie_flat = Flatten()(movie_embedding)\n",
    "\n",
    "  # Concatenate User and Movie Embeddings\n",
    "  # concat = Concatenate()([user_flat, movie_flat])\n",
    "  concat = Dot(axes=1)([user_flat, movie_flat])\n",
    "\n",
    "  # Dense Layer\n",
    "  dense1 = Dense(130, activation='relu')(concat)\n",
    "\n",
    "  # Output Layer\n",
    "  output = Dense(1)(dense1)\n",
    "\n",
    "  # Model\n",
    "  model = Model(inputs=[user_input, movie_input], outputs=output)\n",
    "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR1VTvFlgAwY"
   },
   "source": [
    "# Generate Recommendation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dLgjISyZfvwX"
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "movies = pd.read_csv('drive/MyDrive/ml-25m/movies.csv')\n",
    "ratings = pd.read_csv('drive/MyDrive/ml-25m/ratings.csv')\n",
    "tags = pd.read_csv('drive/MyDrive/ml-25m/tags.csv')\n",
    "\n",
    "data = pd.merge(ratings, movies, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nJ1JOHzZfv0H"
   },
   "outputs": [],
   "source": [
    "def generate_recommendations(user_id, model, top_n=10):\n",
    "    CF_model = model\n",
    "    user_movies = data[data['userId'] == user_id]['movieId'].unique()\n",
    "    unrated_movies = movies[~movies['movieId'].isin(user_movies)]['movieId'].unique()\n",
    "\n",
    "    predictions = CF_model.predict([pd.Series([user_id] * len(unrated_movies)), unrated_movies])\n",
    "    movie_ratings = pd.DataFrame({'movieId': unrated_movies, 'predicted_rating': predictions.flatten()})\n",
    "    top_recommendations = movie_ratings.nlargest(top_n, 'predicted_rating')\n",
    "    top_recommendations = pd.merge(top_recommendations, movies, on = 'movieId')\n",
    "\n",
    "    # print(new_frame)\n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tekGIZGgPJE"
   },
   "source": [
    "# Predict sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26A9_w7tfv3J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iJceJ-SIBCNM"
   },
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence, model, saved_model):\n",
    "  # new_sentence = re.sub(r'[^a-zA-Z ]', '', new_sentence)\n",
    "  # new_sentence = okt.morphs(new_sentence, stem=True) # Tokenizer\n",
    "  # new_sentence = [word for word in new_sentence if not word in stopwords]\n",
    "\n",
    "  # Create a new model instance\n",
    "  sentiment_analysis_model = model\n",
    "\n",
    "  # Load the previously saved weights\n",
    "  sentiment_analysis_model.load_weights(saved_model)\n",
    "\n",
    "  new_sentence = clean_text(new_sentence)\n",
    "  encoded = tokenizer.texts_to_sequences([new_sentence]) # Encoding\n",
    "\n",
    "  encoded = np.array(encoded)\n",
    "  pad_new = pad_sequences(encoded, maxlen=max_length,\n",
    "                         padding=padding_type,\n",
    "                         truncating=trunc_type)\n",
    "  score = float(sentiment_analysis_model.predict(pad_new)) # Prediction\n",
    "  sentiment = 0\n",
    "\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% positive review.\\n\".format(score * 100))\n",
    "    sentiment = 1 # positive\n",
    "  else:\n",
    "    print(\"{:.2f}% negative review.\\n\".format((1 - score) * 100))\n",
    "    sentiment = 0 # negative\n",
    "  return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "3UVnE51cQ7eN",
    "outputId": "2a9c536a-e491-401e-9553-1fa37f334bde"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e49705779b03>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'''Surrounded by the warmth of sunshine and the laughter of loved ones'''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_model' is not defined"
     ]
    }
   ],
   "source": [
    "sentiment_predict('''Surrounded by the warmth of sunshine and the laughter of loved ones''', new_model, saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB2fq9vPgWzD"
   },
   "source": [
    "# Call the saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5_hbzunygY8K"
   },
   "outputs": [],
   "source": [
    "CF_saved_model = \"/content/drive/MyDrive/CF_training/ckpt-030.ckpt\"\n",
    "SA_saved_weights = \"/content/drive/MyDrive/sentiment_training/ckpt-005.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "tbp9EM-jgY-6"
   },
   "outputs": [],
   "source": [
    "MR_model = CF_model(data)\n",
    "MR_model.load_weights(CF_saved_model)\n",
    "sa_model = sentiment_analysis_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUEPY1MWgb8p",
    "outputId": "d3e1aebd-2d49-4cfb-e778-00e2bf068f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1948/1948 [==============================] - 2s 1ms/step\n",
      "\n",
      "Top Movie Recommendations:\n",
      "                                                 title                           genres  predicted_rating\n",
      "                       The girl With the Sulfur (2013)                 Children|Fantasy          4.419818\n",
      "                              Land of No Return (1978)               Adventure|Children          4.419811\n",
      "                             Tender Loving Care (1974)                            Drama          4.419807\n",
      "                                          Грачи (1983)               (no genres listed)          4.419806\n",
      "                                    Flying Boys (2004)                            Drama          4.419798\n",
      "                               Babes In Toyland (1987) Adventure|Children|Drama|Fantasy          4.419798\n",
      "                                    The Victors (1963)                        Drama|War          4.419795\n",
      "Kurara: The Dazzling Life of Hokusai's Daughter (2017)                            Drama          4.419795\n",
      "                              Framed for Murder (2007)                 Mystery|Thriller          4.419793\n",
      "                                   Cosmopolitan (2003)                    Drama|Romance          4.419789\n"
     ]
    }
   ],
   "source": [
    "recommendations = generate_recommendations(21, MR_model)\n",
    "print(\"\\nTop Movie Recommendations:\")\n",
    "print(recommendations[['title','genres', 'predicted_rating']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vussrwkghXxv"
   },
   "source": [
    "#  Re-Rating: Categorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "S0jes5Tdgejo"
   },
   "outputs": [],
   "source": [
    "genere_for_negative = ['Comedy', 'Action', 'Adventure', 'Drama', 'Fantasy','Sci-Fi']\n",
    "genre_for_positive = ['Comedy', 'Horror', \"Children's\", 'Romance', 'Musical', 'Animation']\n",
    "neutral_genres = ['Documentary', 'Film-Noir','Mystery','Thriller','War','Western', '(no genres listed)']\n",
    "genere_for_negative_new_lst = genere_for_negative + neutral_genres\n",
    "genre_for_positive_new_lst = genere_for_negative + neutral_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "R3LyGnlghbHW"
   },
   "outputs": [],
   "source": [
    "def re_rank(data, new_lst):\n",
    "  for i in range (len(data[\"genres\"])):\n",
    "    temp = []\n",
    "    temp = data[\"genres\"][i].split(\"|\")\n",
    "    for j in range(len(temp)):\n",
    "      if temp[j] in genere_for_negative_new_lst:\n",
    "        temp[j] = 1\n",
    "      else:\n",
    "        temp[j] = 0\n",
    "    genre_point = sum(temp)\n",
    "    data[\"predicted_rating\"][i] = data[\"predicted_rating\"][i] + genre_point\n",
    "    temp = []\n",
    "    sorted_data = data.sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "  return print(sorted_data[['title','genres', 'predicted_rating']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNHO8Wkthdmo"
   },
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ce5oe9NmhbKZ",
    "outputId": "b03df95b-14af-4f6c-d169-4f365e1cb5f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is your day?: I feel so bad\n",
      "1/1 [==============================] - 1s 831ms/step\n",
      "96.19% negative review.\n",
      "\n",
      "                                                 title                           genres  predicted_rating\n",
      "                               Babes In Toyland (1987) Adventure|Children|Drama|Fantasy          7.419798\n",
      "                                    The Victors (1963)                        Drama|War          6.419795\n",
      "                              Framed for Murder (2007)                 Mystery|Thriller          6.419793\n",
      "                       The girl With the Sulfur (2013)                 Children|Fantasy          5.419818\n",
      "                              Land of No Return (1978)               Adventure|Children          5.419811\n",
      "                             Tender Loving Care (1974)                            Drama          5.419807\n",
      "                                          Грачи (1983)               (no genres listed)          5.419806\n",
      "                                    Flying Boys (2004)                            Drama          5.419798\n",
      "Kurara: The Dazzling Life of Hokusai's Daughter (2017)                            Drama          5.419795\n",
      "                                   Cosmopolitan (2003)                    Drama|Romance          5.419789\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-394ece87e401>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"predicted_rating\"][i] = data[\"predicted_rating\"][i] + genre_point\n"
     ]
    }
   ],
   "source": [
    "answer = input(\"How is your day?: \")\n",
    "response = sentiment_predict(answer,sa_model, SA_saved_weights)\n",
    "if response == 0:\n",
    "  re_rank(recommendations, genere_for_negative_new_lst)\n",
    "  print(0)\n",
    "if response == 1:\n",
    "  re_rank(recommendations, genre_for_positive_new_lst)\n",
    "  print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNba7geWhkwA",
    "outputId": "a3a1a705-64c8-4774-fb81-6b35c81dd6d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is your day?: Surrounded by the warmth of sunshine and the laughter of loved ones, every moment becomes a cherished memory.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "67.94% positive review.\n",
      "\n",
      "The following movie lists for when you are feeling good!\n",
      "                                                 title                           genres  predicted_rating\n",
      "                               Babes In Toyland (1987) Adventure|Children|Drama|Fantasy          7.419798\n",
      "                                    The Victors (1963)                        Drama|War          6.419795\n",
      "                              Framed for Murder (2007)                 Mystery|Thriller          6.419793\n",
      "                       The girl With the Sulfur (2013)                 Children|Fantasy          5.419818\n",
      "                              Land of No Return (1978)               Adventure|Children          5.419811\n",
      "                             Tender Loving Care (1974)                            Drama          5.419807\n",
      "                                          Грачи (1983)               (no genres listed)          5.419806\n",
      "                                    Flying Boys (2004)                            Drama          5.419798\n",
      "Kurara: The Dazzling Life of Hokusai's Daughter (2017)                            Drama          5.419795\n",
      "                                   Cosmopolitan (2003)                    Drama|Romance          5.419789\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-394ece87e401>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"predicted_rating\"][i] = data[\"predicted_rating\"][i] + genre_point\n"
     ]
    }
   ],
   "source": [
    "answer = input(\"How is your day?: \")\n",
    "response = sentiment_predict(answer,sa_model, SA_saved_weights)\n",
    "if response == 0:\n",
    "  print(\"The following movie lists for when you are feeling bad\")\n",
    "\n",
    "  re_rank(recommendations, genere_for_negative_new_lst)\n",
    "  print(0)\n",
    "if response == 1:\n",
    "  print(\"The following movie lists for when you are feeling good!\")\n",
    "  re_rank(recommendations, genre_for_positive_new_lst)\n",
    "  print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hS3ZfGgO1ppj"
   },
   "outputs": [],
   "source": [
    "Surrounded by the warmth of sunshine and the laughter of loved ones, every moment becomes a cherished memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9Z0QXaKi5r5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
